{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/4　進捗報告と本日の質問\n",
    "\n",
    "＜進捗＞\n",
    "ロジスティック回帰、SVM,木、ランダムフォレスト、ｱﾀﾞﾌﾞｰｽﾄのモデルそれぞれで、正則化・標準化・ハイパーパラメータをGridsearchで探索の場合での精度を確かめてみました。\n",
    "組み込み法で躓いています。\n",
    "\n",
    "＜本日お伺いしたいこと＞  \n",
    "1.正則化について  \n",
    "木・ランダムフォレスト・ｱﾀﾞﾌﾞｰｽﾄは不純度や情報量のばらつきでモデルを構築するので、正則化の考え方はない？  \n",
    "\n",
    "\n",
    "2.標準化について  \n",
    "数値の「goal」「days」にしか行わず、get_dummiesで処理したカテゴリ変数には行いませんでした。その考え方であっているか？  \n",
    "\n",
    "3.Slackでお伺いした、SVMの処理時間がかかる件  \n",
    "ハイパーパラメータ探索を全体のデータの5%、モデル構築のデータを全体の20%で行いました。このような考え方であっているか？「【林優夏】3月4日ビデオチャット用　SVM（標準化＋params）」のnotebookです。  \n",
    "\n",
    "4.組み込み法について  \n",
    "エラーが出てしまう（このnotebook）  \n",
    "\n",
    "5.標準化・組み込み法・ハイパーパラメータ探索の順序について  \n",
    "標準化を行い、組み込み法で変数を選択→その後ハイパーパラメータ探索で正則化をl1にするかl2にするか選んだり、他のパラメータを設定する、という基本的な流れでいいか  \n",
    "\n",
    "6.name列について\n",
    "「【林優夏】3月4日ビデオチャット用　nameの考察」のnotebookの様な考え方をしてみましたのでご意見伺いたいです"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "①データの読み込み・前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\yuka0\\Documents\\skillupai\\ML\\DAY1\\homework\\ks-projects-201801.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#募集期間の加工\n",
    "df['deadline'] = pd.to_datetime(df[\"deadline\"])\n",
    "df[\"launched\"] = pd.to_datetime(df[\"launched\"])\n",
    "\n",
    "df[\"days\"] = (df[\"deadline\"] - df[\"launched\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stateが成功と失敗以外のデータを削除\n",
    "#ID削除\n",
    "#nameとcategoryも削除\n",
    "#daysを募集期間で出したのでdf[\"deadline\"]とdf[\"launched\"]も削除\n",
    "#backers,pledgedと、usd pledgedより右はモデルにいれちゃだめだと思うので削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの削除・加工\n",
    "df = df[(df[\"state\"] == \"successful\") | (df[\"state\"] == \"failed\")]\n",
    "df = df.drop([\"ID\",\"name\",\"deadline\",\"launched\",\"backers\",\"pledged\",\"usd pledged\",\"usd_pledged_real\",\"usd_goal_real\"], axis=1)\n",
    "df[\"state\"] = df[\"state\"].replace(\"failed\",0)\n",
    "df[\"state\"] = df[\"state\"].replace(\"successful\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④カテゴリ変数処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#カテゴリ変数処理\n",
    "df = pd.get_dummies(df,drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuka0\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\yuka0\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#標準化\n",
    "stdsc = StandardScaler()\n",
    "df[\"goal\"] = stdsc.fit_transform(df[[\"goal\"]].values)\n",
    "df[\"days\"] = stdsc.fit_transform(df[[\"days\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "②データ分割・変数選択（組み込み法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ分割\n",
    "train_data = df.drop(\"state\", axis=1)\n",
    "y = df[\"state\"].values\n",
    "X = train_data.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "組み込み法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LassoCV(alphas=None, copy_X=True, cv=10, eps=0.001, fit_intercept=True,\n",
       "    max_iter=1000, n_alphas=100, n_jobs=None, normalize=True,\n",
       "    positive=False, precompute='auto', random_state=None,\n",
       "    selection='cyclic', tol=0.0001, verbose=False),\n",
       "        max_features=None, norm_order=1, prefit=False, threshold=1e-05)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LassoCV(normalize = True, cv = 10)\n",
    "sfm = SelectFromModel(estimator, threshold = 1e-5)\n",
    "sfm.fit(X_train_selected,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has a different shape than during fitting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-27e55aefb602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X has a different shape than during fitting.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has a different shape than during fitting."
     ]
    }
   ],
   "source": [
    "X_train_selected = sfm.transform(X_train)\n",
    "X_test_selected = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SGDClassifier()\n",
    "classifier.fit(X_train_selected, y_train)\n",
    "classifier.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_support関数で使用する特徴のインデックスを使用\n",
    "# Trueになっている特徴が使用する特徴\n",
    "sfm.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 削除すべき特徴の名前を取得 \n",
    "removed_idx = ~sfm.get_support()\n",
    "train_data.columns[removed_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ハイパーパラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "parameters = {'penalty':['l1', 'l2'], 'max_iter':[5000,30000], 'tol':[1e-10,1e-1]} # ここを編集する\n",
    "model = classifier\n",
    "clf = GridSearchCV(model, parameters, cv=3,)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
